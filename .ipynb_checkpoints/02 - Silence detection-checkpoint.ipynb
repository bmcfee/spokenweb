{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Silence detection\n",
    "\n",
    "In this notebook, you'll implement a basic silence detector.  This will introduce you to basic feature extraction and audio manipulation in python.\n",
    "\n",
    "You can use this to segment speech recordings into short utterances, but the point is more to get you familiar with how it looks to process audio programmatically.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Again, we begin by setting up our envrionment.  This time, we'll do it all in one block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll work with an example provided in the repository.\n",
    "# There are many files in this directory, but we'll start with the first one.\n",
    "# The later examples (higher numbers) have more difficult noise conditions.\n",
    "\n",
    "y, sr = librosa.load('silence_examples/2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play it back, so we know what our data sounds like\n",
    "Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the spectrogram to see what the data looks like\n",
    "D = librosa.stft(y)\n",
    "S = np.abs(D)\n",
    "S_db = librosa.amplitude_to_db(S, ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(S_db, x_axis='time', y_axis='linear')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What can we see here?\n",
    "\n",
    "- Where is the energy?\n",
    "- How can we detect regions with high energy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The feature module\n",
    "\n",
    "`librosa.feature` contains methods for extracting different descriptive features from audio.  These might encode aspects of loudness, rhythm, pitch, harmony, noisiness, etc.\n",
    "\n",
    "As a first step, let's look at the \"energy\" in each time step as represented by the root-mean-square (RMS) values.  This is computed by `librosa.feature.rms`.\n",
    "\n",
    "Feature methods can be applied to either the audio time series `(y)` or a pre-computed spectrogram `(S)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = librosa.feature.rms(S=S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this look like?\n",
    "energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy is a 2-dimensional array:\n",
    "#  The first dimension indexes the feature(s) (energy)\n",
    "#  The second dimension indexes the time axis.\n",
    "\n",
    "# It's hard to read this directly, but we can visualize it with a plot using matplotlib.\n",
    "# To do this, we'll want to know the times corresponding to each measurement.\n",
    "# We can get this as follows:\n",
    "\n",
    "times = librosa.times_like(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can plot the data\n",
    "plt.plot(times, energy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we can plot in decibels\n",
    "plt.plot(times, librosa.amplitude_to_db(energy[0], ref=np.max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does this show?\n",
    "\n",
    "The `rms` function looks at the total energy within each frame of 2048 samples.\n",
    "\n",
    "At the sampling rate of `sr=22050`, this corresponds to about 93ms of audio.\n",
    "\n",
    "When we convert to decibels (relative to the maximum), we see that the energy is usually pretty high (during speech), and dips down low in between.  We can use this to determine a decibel threshold for determining silence.\n",
    "\n",
    "In fact, we have a function built in that does exactly this calculation: you give it a decibel threshold, and it will return a list of time intervals (measured in samples) of detected regions that are above the threshold.  It's called `librosa.effects.split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.effects.split(y=y, top_db=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use it, first save the intervals into an array\n",
    "intervals = librosa.effects.split(y=y, top_db=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can slice out the first interval\n",
    "y_slice = y[intervals[0, 0]:intervals[0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=y_slice, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the second slice\n",
    "y_slice2 = y[intervals[1, 0]:intervals[1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=y_slice2, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hmmm....\n",
    "\n",
    "That doesn't work all that well.  What's going on?\n",
    "\n",
    "Let's take a closer look at the spectrum.  In this case, we'll use a logarithmic frequency axis to get a better view of the low frequencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(S_db, x_axis='time', y_axis='log')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise!\n",
    "\n",
    "These signals have a lot of energy in the low frequencies.\n",
    "\n",
    "Let's use scipy to filter out the low frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll make a high-pass, order-6 butterworth filter\n",
    "# Let's put the cutoff at 64 Hz\n",
    "\n",
    "# Don't worry about the details here: this is a pretty standard way\n",
    "# to do filtering\n",
    "\n",
    "b, a = scipy.signal.butter(6, 64, btype='high', fs=sr)\n",
    "\n",
    "# Now that we have our coefficients, we can filter the signal\n",
    "y_high = scipy.signal.filtfilt(b, a, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's listen to our output\n",
    "Audio(data=y_high, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's compute the spectrogram again and plot it\n",
    "D_high = librosa.stft(y_high)\n",
    "S_high = np.abs(D_high)\n",
    "S_high_db = librosa.amplitude_to_db(S_high, ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(S_high_db, x_axis='time', y_axis='log')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No more low-frequency noise!\n",
    "\n",
    "Let's see how that impacts our silence detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_high = librosa.feature.rms(S=S_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or we can plot in decibels\n",
    "plt.plot(times, librosa.amplitude_to_db(energy_high[0], ref=np.max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's much more like it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_splits = librosa.effects.split(y=y_high, top_db=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=y[new_splits[0, 0]:new_splits[0, 1]], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=y[new_splits[1, 0]:new_splits[1, 1]], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=y[new_splits[2, 0]:new_splits[2, 1]], rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping up\n",
    "\n",
    "In this notebook, you've done the following:\n",
    "\n",
    "1. Computed features from audio and visualized the result\n",
    "2. Implemented rules for splitting silence from non-silence\n",
    "3. Iterated on the design by incorporating signal filtering\n",
    "\n",
    "Once you've completed this part, try loading another example file.  Does the method still work, or does it need more refinement?  What might you do differently?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
